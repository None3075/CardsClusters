{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93fc5cad-89ee-405b-8d43-d6305f8488fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "#The five types of plays are classified by their riskiness.\n",
    "#It helps to identify the tactics of the AI\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TGVD_GenericQuery\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "path_training = \"CardsParquetData/trained_blackjack.parquet\"\n",
    "path_match = \"CardsParquetData/played_blackjack.parquet\"\n",
    "\n",
    "df_train = spark.read.parquet(path_training)\n",
    "df_play = spark.read.parquet(path_match)\n",
    "df_train = df_train.withColumn(\"index\", (monotonically_increasing_id() + 1))\n",
    "df_play = df_play.withColumn(\"index\", (monotonically_increasing_id() + 1))\n",
    "\n",
    "count_play = df_play.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc00ac2-d7bd-477c-9197-1ef9a097e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recycled part from query 1\n",
    "#-----------------------------------------------------\n",
    "#Using the dataset where the model has been trained\n",
    "#-----------------------------------------------------\n",
    "CHUNK_SIZE = 500\n",
    "from pyspark.sql.functions import floor, expr, when, coalesce\n",
    "df_clean = df_train.select(\n",
    "    col(\"index\"),\n",
    "    col(\"Shown_cards\").alias(\"Hand_-1\"),\n",
    "    col(\"Hand 0\").alias(\"Hand_0\"),\n",
    "    col(\"Hand 1\").alias(\"Hand_1\"),\n",
    "    col(\"Hand 2\").alias(\"Hand_2\"),\n",
    "    col(\"Hand 3\").alias(\"Hand_3\"),\n",
    "    col(\"Hand 4\").alias(\"Hand_4\"),\n",
    "    col(\"Hand 5\").alias(\"Hand_5\"),\n",
    "    col(\"Hand 6\").alias(\"Hand_6\"),\n",
    "    col(\"Hand 7\").alias(\"Hand_7\")\n",
    ")\n",
    "df_chunks = df_clean.withColumn(\"Chunk Number\", floor(col(\"index\")/CHUNK_SIZE))\n",
    "hand_cols = [\"Hand_0\", \"Hand_1\", \"Hand_2\", \"Hand_3\", \"Hand_4\", \"Hand_5\", \"Hand_6\", \"Hand_7\"]\n",
    "df_moves = df_chunks.withColumn(\"n_moves\",\n",
    "    1 + sum([\n",
    "        when((col(f\"Hand_{i-1}\")[0].isNotNull()) & (col(f\"Hand_{i-1}\")[0] != col(f\"Hand_{i-2}\")[0]), 1).otherwise(0)\n",
    "        for i in range(1, len(hand_cols))\n",
    "    ])\n",
    ")\n",
    "rev_hand_cols = [\"Hand_7\", \"Hand_6\", \"Hand_5\", \"Hand_4\", \"Hand_3\", \"Hand_2\", \"Hand_1\", \"Hand_0\"]\n",
    "df_result_train = df_moves.withColumn(\"Final_Hand\", coalesce(*[col(c) for c in rev_hand_cols]))\n",
    "df_result_train = df_result_train.withColumn(\n",
    "    \"Result\",\n",
    "    when(col(\"Final_Hand\").isNull(), \"Unknown\")\n",
    "    .when(col(\"Final_Hand\")[0] > 21, \"Lose\")\n",
    "    .when(col(\"Final_Hand\")[1] > 21, \"Win\")\n",
    "    .when(col(\"Final_Hand\")[0] > col(\"Final_Hand\")[1], \"Win\")\n",
    "    .when(col(\"Final_Hand\")[0] < col(\"Final_Hand\")[1], \"Lose\")\n",
    "    .otherwise(\"Draw\")\n",
    ")\n",
    "probabilities = [0.25, 0.5, 0.75]\n",
    "quartiles = df_result_train.select(\"n_moves\").approxQuantile(\"n_moves\", probabilities, 0.01)\n",
    "df_risk_train = df_moves.withColumn(\n",
    "    \"Risk Level\",\n",
    "    when(col(\"n_moves\") <= quartiles[0], \"Safe\")\n",
    "    .when((col(\"n_moves\") > quartiles[0]) & (col(\"n_moves\") <= quartiles[1]), \"Tactical\")\n",
    "    .when((col(\"n_moves\") > quartiles[1]) & (col(\"n_moves\") <= quartiles[2]), \"Risky\")\n",
    "    .otherwise(\"Suicidal\")\n",
    ")\n",
    "\n",
    "#-----------------------------------------------------\n",
    "#Using the dataset of the model playing against itself\n",
    "#-----------------------------------------------------\n",
    "df_clean = df_play.select(\n",
    "    col(\"index\"),\n",
    "    col(\"Shown_cards\").alias(\"Hand_-1\"),\n",
    "    col(\"Hand 0\").alias(\"Hand_0\"),\n",
    "    col(\"Hand 1\").alias(\"Hand_1\"),\n",
    "    col(\"Hand 2\").alias(\"Hand_2\"),\n",
    "    col(\"Hand 3\").alias(\"Hand_3\"),\n",
    "    col(\"Hand 4\").alias(\"Hand_4\"),\n",
    "    col(\"Hand 5\").alias(\"Hand_5\")\n",
    ")\n",
    "hand_cols = [\"Hand_0\", \"Hand_1\", \"Hand_2\", \"Hand_3\", \"Hand_4\", \"Hand_5\"]\n",
    "df_moves = df_clean.withColumn(\"n_moves\",\n",
    "    1 + sum([\n",
    "        when((col(f\"Hand_{i-1}\")[0].isNotNull()) & (col(f\"Hand_{i-1}\")[0] != col(f\"Hand_{i-2}\")[0]), 1).otherwise(0)\n",
    "        for i in range(1, len(hand_cols))\n",
    "    ])\n",
    ")\n",
    "rev_hand_cols = [\"Hand_5\", \"Hand_4\", \"Hand_3\", \"Hand_2\", \"Hand_1\", \"Hand_0\"]\n",
    "df_result_train = df_moves.withColumn(\"Final_Hand\", coalesce(*[col(c) for c in rev_hand_cols]))\n",
    "df_result_train = df_result_train.withColumn(\n",
    "    \"Result\",\n",
    "    when(col(\"Final_Hand\").isNull(), \"Unknown\")\n",
    "    .when(col(\"Final_Hand\")[0] > 21, \"Lose\")\n",
    "    .when(col(\"Final_Hand\")[1] > 21, \"Win\")\n",
    "    .when(col(\"Final_Hand\")[0] > col(\"Final_Hand\")[1], \"Win\")\n",
    "    .when(col(\"Final_Hand\")[0] < col(\"Final_Hand\")[1], \"Lose\")\n",
    "    .otherwise(\"Draw\")\n",
    ")\n",
    "probabilities = [0.25, 0.5, 0.75]\n",
    "quartiles = df_result_train.select(\"n_moves\").approxQuantile(\"n_moves\", probabilities, 0.01)\n",
    "df_risk_play = df_moves.withColumn(\n",
    "    \"Risk Level\",\n",
    "    when(col(\"n_moves\") <= quartiles[0], \"Safe\")\n",
    "    .when((col(\"n_moves\") > quartiles[0]) & (col(\"n_moves\") <= quartiles[1]), \"Tactical\")\n",
    "    .when((col(\"n_moves\") > quartiles[1]) & (col(\"n_moves\") <= quartiles[2]), \"Risky\")\n",
    "    .otherwise(\"Suicidal\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de1e0469-31ff-45e2-8293-effe35112580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----------+\n",
      "|Chunk Number|Risk Level|count|Proportion|\n",
      "+------------+----------+-----+----------+\n",
      "|           0|  Suicidal|   16|       3.2|\n",
      "|           0|     Risky|   90|      18.0|\n",
      "|           0|      Safe|  393|      78.6|\n",
      "|           1|  Suicidal|   41|       8.2|\n",
      "|           1|     Risky|  120|      24.0|\n",
      "|           1|      Safe|  339|      67.8|\n",
      "|           2|  Suicidal|   29|       5.8|\n",
      "|           2|     Risky|  167|      33.4|\n",
      "|           2|      Safe|  304|      60.8|\n",
      "|           3|  Suicidal|   35|       7.0|\n",
      "|           3|     Risky|  177|      35.4|\n",
      "|           3|      Safe|  288|      57.6|\n",
      "|           4|     Risky|    1|       0.2|\n",
      "+------------+----------+-----+----------+\n",
      "\n",
      "+----------+-----+----------+\n",
      "|Risk Level|count|Proportion|\n",
      "+----------+-----+----------+\n",
      "|Suicidal  |76   |7.6       |\n",
      "|Risky     |321  |32.1      |\n",
      "|Safe      |603  |60.3      |\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#--------------\n",
    "#   QUERY 2\n",
    "#--------------\n",
    "\n",
    "#The types of strategies, (safe, tactical, risky…) and it’s proportion\n",
    "#It helps to identify which strategy is the common one.\n",
    "from pyspark.sql.functions import round\n",
    "\n",
    "df_fin = df_risk_train.select(col(\"Chunk Number\"), col(\"n_moves\"), col(\"Risk Level\")).groupBy(\"Chunk Number\", \"Risk Level\").count().orderBy(\"Chunk Number\", \"count\")\n",
    "df_query2 = df_fin.withColumn(\"Proportion\", round(col(\"count\")*100/CHUNK_SIZE, 2))\n",
    "df_query2.show()\n",
    "\n",
    "df_fin = df_risk_play.select(col(\"n_moves\"), col(\"Risk Level\")).groupBy(\"Risk Level\").count().orderBy(\"count\")\n",
    "df_query2 = df_fin.withColumn(\"Proportion\", round(col(\"count\")*100/count_play, 2))\n",
    "df_query2.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d17f31-565a-41f0-8a85-4a0c9b609753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----+----------+------------+\n",
      "|Chunk Number|Risk Level|count|Proportion|Unique_Moves|\n",
      "+------------+----------+-----+----------+------------+\n",
      "|0           |Suicidal  |16   |3.2       |[5, 4]      |\n",
      "|0           |Risky     |90   |18.0      |[3]         |\n",
      "|0           |Safe      |393  |78.6      |[1, 2]      |\n",
      "|1           |Suicidal  |41   |8.2       |[5, 4]      |\n",
      "|1           |Risky     |120  |24.0      |[3]         |\n",
      "|1           |Safe      |339  |67.8      |[1, 2]      |\n",
      "|2           |Suicidal  |29   |5.8       |[5, 4]      |\n",
      "|2           |Risky     |167  |33.4      |[3]         |\n",
      "|2           |Safe      |304  |60.8      |[1, 2]      |\n",
      "|3           |Suicidal  |35   |7.0       |[5, 4]      |\n",
      "|3           |Risky     |177  |35.4      |[3]         |\n",
      "|3           |Safe      |288  |57.6      |[1, 2]      |\n",
      "|4           |Risky     |1    |0.2       |[3]         |\n",
      "+------------+----------+-----+----------+------------+\n",
      "\n",
      "+----------+-----+----------+------------+\n",
      "|Risk Level|count|Proportion|Unique_Moves|\n",
      "+----------+-----+----------+------------+\n",
      "|Suicidal  |76   |15.2      |[5, 6, 4]   |\n",
      "|Risky     |321  |64.2      |[3]         |\n",
      "|Safe      |603  |120.6     |[1, 2]      |\n",
      "+----------+-----+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Shows how many unique move values (n_moves) there are per risk type, indicating variability in the strategy\n",
    "from pyspark.sql.functions import count, collect_set\n",
    "\n",
    "df_fin_train = df_risk_train.select(\"Chunk Number\", \"Risk Level\", \"n_moves\") \\\n",
    "    .groupBy(\"Chunk Number\", \"Risk Level\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"count\"),\n",
    "        round((count(\"*\") * 100 / CHUNK_SIZE), 2).alias(\"Proportion\"),\n",
    "        collect_set(\"n_moves\").alias(\"Unique_Moves\")\n",
    "    ) \\\n",
    "    .orderBy(\"Chunk Number\", \"count\")\n",
    "\n",
    "df_fin_train.show(truncate=False)\n",
    "\n",
    "df_fin_play = df_risk_play.select(\"Risk Level\", \"n_moves\") \\\n",
    "    .groupBy(\"Risk Level\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"count\"),\n",
    "        round((count(\"*\") * 100 / CHUNK_SIZE), 2).alias(\"Proportion\"),\n",
    "        collect_set(\"n_moves\").alias(\"Unique_Moves\")\n",
    "    ) \\\n",
    "    .orderBy(\"count\")\n",
    "\n",
    "df_fin_play.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
